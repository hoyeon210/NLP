{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff320c9-e570-4658-99af-2eb37a090371",
   "metadata": {},
   "source": [
    "### Bag of Words(BoW)\n",
    "- 단어의 순서는 고려하지 않고 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 방법\n",
    "- 우선, 각 단어에 고유한 정수 인덱스를 부여\n",
    "- 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듬\n",
    "- scikit-learn의 CountVectorizer를 이용하여 간단히 BoW를 구성할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bea28db-8bbe-4255-ae93-da201c44f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3584f4-7268-4831-88b5-d4dc79a870e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21af3425-4958-498e-bd7f-6473f35736a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf44f78-f3fd-4695-b0f9-c32b8863db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]]\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c5d925-6cf9-43b5-8ebf-c4f4b3a8266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0번인덱스, 2번인덱스, 6번인덱스가 1번씩 나왔다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430ea129-a304-43aa-854e-3f34a4f080d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = ['오늘 점심 맛없었어', '내일 점심 또 그럴까']\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8894f2e-5b74-4e56-8460-47c5555414e6",
   "metadata": {},
   "source": [
    "### 문서 단어 행렬(Document-Term Matrix, DTM)\n",
    "- 서로 다른 문서들의 BoW들을 결합한 표현 방법  \n",
    "- 다수의 문서에 등장하는 각 단어들의 빈도를 행렬로 표현한 것  \n",
    "- 문서1 : 호기심 많은 고양이  \n",
    "- 문서2 : 꼬리가 긴 고양이  \n",
    "- 문서3 : 호기심 많은 강아지  \n",
    "- 문서4 : 철수는 동물을 좋아해요 \n",
    "|      |강아지|고양이|긴|꼬리가|동물을|많은|좋아해요|철수는|호기심|\n",
    "|------|-----|-----|--|-----|-----|---|-------|-----|-----|\n",
    "|문서1  |  0  |  1  | 0|  0  |  0 | 1  |   0   |  0  |  1  |\n",
    "|문서2  |  0  |  1  |1|  1  |  0 | 0  |   0   |  0  |  0  |\n",
    "|문서3  |  1  |  0  |0|  0  |  0 | 1  |   0   |  0  |  1  |\n",
    "|문서4  |  0  |  0  |0|  0  |  1 | 0  |   1   |  1  |  0  |  \n",
    "- 각 문서에서 등장한 단어의 빈도를 행렬값으로 표시  \n",
    "- 문서들을 서로 비교할 수 있도록 수치화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44277e9c-c647-46cf-a419-5a9bb50afbac",
   "metadata": {},
   "source": [
    "### 문서 단어 행렬의 한계\n",
    "\n",
    "1. 희소 표현\n",
    "\n",
    "- one-hot encoding 방식의 벡터는 단어 집합의 크기가 벡터의 차원이 됨(대부분의 값이 0)\n",
    "- 공간과 계산 리소스의 낭비\n",
    "\n",
    "2. 단순 빈도수 기반 접근\n",
    "\n",
    "- 여러 문서에 등장하는 모든 단어에 대해서 빈도수만을 사용하는 한계\n",
    "- 각 문서에는 중요한 단어와 불필요한 단어가 혼재되어 있음\n",
    "- DTM에 불용어와 중요한 단어에 대한 가중치를 부여하는 방법이 필요(the, a 같은거..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dd5afe-94ad-4449-ac11-8c3b2c98d545",
   "metadata": {},
   "source": [
    "### TF-IDF(Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d204b-7341-4a8d-82c2-e312ed16519d",
   "metadata": {},
   "source": [
    "- 단어의 빈도와 역 문서 빈도를 사용하여 DTM내의 각 단어들마다 중요한 정도의 가중치를 부여하는 방법  \n",
    "- 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰임  \n",
    "- TF-IDF 는 TF와 IDF를 곱한 값을 의미  \n",
    "- 문서를 d, 단어를 t, 문서의 총 개수를 n이라고 하면  \n",
    "1) tf(d, t): 특정 문서 d에서의 특정 단어 t의 등장 회수  \n",
    "2) df(t) : 특정 단어 t가 등장한 문서의 수  \n",
    "3) idf(d, t) : df(t)에 반비례하는 수  \n",
    "idf(d, t) = log(n / (1 + df(t)))\n",
    "- 총 문서의 수 n이 급격히 증가하게 되면 IDF의 값이 기하급수적으로 커지는 것을 방지하기 위해 log를 사용  \n",
    "- 특정 단어가 전체 문서에서 등장하지 않게 되는 경우 분모가 0이 되는 것을 방지하기 위해 1을 더함  \n",
    "- TF-IDF는 모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단  \n",
    "- 특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단  \n",
    "- TF-IDF 값이 낮으면 중요도가 낮다고 판단  \n",
    "- 예를 들어 영어에서 the 나 a와 같은 불용어의 경우 모든 문서에 자주 등장하기 때문에 이런 불용어들의 TF-IDF 값은 다른 단어에 비해서 낮아지게 됨  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bcb2915-d281-41ae-9452-d07efe24e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ba13ab-9686-4808-b7a7-07c380e1a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de96d1e0-7cf6-476a-abfe-102916e442b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0deb051e-d8c4-4c7c-acbc-c2b738112ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[3]]\n",
    "print(tfidf_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dd6ae24-2600-4d4d-a79a-9b517944b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인덱스 1번, 3번, 7번, 9번 중  3번 9번이 tf-idf 값이 크다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02e1a24-7959-455a-abca-dc550229e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027 0.         0.57735027 0.         0.         0.\n",
      "  0.57735027 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.52640543 0.         0.66767854\n",
      "  0.         0.52640543 0.         0.        ]\n",
      " [0.         0.52640543 0.         0.52640543 0.         0.\n",
      "  0.         0.         0.66767854 0.        ]\n",
      " [0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.transform(text_data).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe08ae-0330-4e77-a809-0618a52e2557",
   "metadata": {},
   "source": [
    "- TF-IDF 값을 사용할 경우, 단순횟수를 이용하는 것보다 각 단어의 특성을 좀 더 잘 반영할 수 있음\n",
    "- 모델에 적용할때도 TfidfVectorizer를 사용하는 것이 일반적으로 더 좋은 결과를 만들어 냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea957e1a-f8cf-4d00-928e-2a35c110a6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
